{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "introduction"
      },
      "source": [
        "# Breast Ultrasound Image Classification\n",
        "\n",
        "This notebook implements a deep learning approach for classifying breast ultrasound images using three different models: DenseNet, ResNet, and EfficientNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## Setup and Environment Configuration\n",
        "\n",
        "First, we'll clone the repository and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_code"
      },
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/vedant7001/Breast-cancer-Ultrasound-classification.git\n",
        "%cd Breast-cancer-Ultrasound-classification\n",
        "\n",
        "# Run the setup script\n",
        "!python colab_setup.py"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_section"
      },
      "source": [
        "## Download and Prepare Dataset\n",
        "\n",
        "Download the Breast Ultrasound Images (BUSI) dataset from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_download"
      },
      "source": [
        "# Install kaggle API if needed\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload your kaggle.json file\n",
        "from google.colab import files\n",
        "print(\"Upload your kaggle.json file (from your Kaggle account settings)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Configure kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download BUSI dataset\n",
        "!kaggle datasets download -d aryashah2k/breast-ultrasound-images-dataset\n",
        "!unzip -q breast-ultrasound-images-dataset.zip -d data/BUSI\n",
        "!rm breast-ultrasound-images-dataset.zip\n",
        "\n",
        "# Check dataset structure\n",
        "!ls -la data/BUSI"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "explore_section"
      },
      "source": [
        "## Explore Dataset\n",
        "\n",
        "Let's explore the dataset structure and visualize some sample images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_code"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "# Check dataset statistics\n",
        "data_dir = 'data/BUSI'\n",
        "classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "\n",
        "class_counts = {}\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    image_files = [f for f in os.listdir(class_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    class_counts[class_name] = len(image_files)\n",
        "\n",
        "print(f\"Classes: {classes}\")\n",
        "print(f\"Images per class: {class_counts}\")\n",
        "\n",
        "# Display sample images from each class\n",
        "plt.figure(figsize=(15, 5*len(classes)))\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    image_files = [f for f in os.listdir(class_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    \n",
        "    # Show 3 random images from each class\n",
        "    if image_files: # Ensure there are images to sample from\n",
        "      sample_images = random.sample(image_files, min(3, len(image_files)))\n",
        "      for j, img_file in enumerate(sample_images):\n",
        "          img_path = os.path.join(class_path, img_file)\n",
        "          img = Image.open(img_path)\n",
        "          \n",
        "          plt.subplot(len(classes), 3, i*3 + j + 1)\n",
        "          plt.imshow(img, cmap='gray' if img.mode == 'L' else None)\n",
        "          plt.title(f\"{class_name}: {img_file}\")\n",
        "          plt.axis('off')\n",
        "                \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## Model Training\n",
        "\n",
        "Train the three model architectures on the BUSI dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_check"
      },
      "source": [
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    !nvidia-smi"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_densenet"
      },
      "source": [
        "# Train DenseNet model\n",
        "!python main.py --config config.json --model densenet --epochs 20"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_resnet"
      },
      "source": [
        "# Train ResNet model\n",
        "!python main.py --config config.json --model resnet --epochs 20"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_efficientnet"
      },
      "source": [
        "# Train EfficientNet model\n",
        "!python main.py --config config.json --model efficientnet --epochs 20"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_section"
      },
      "source": [
        "## Model Evaluation and Comparison\n",
        "\n",
        "Evaluate all three models and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_models_code"
      },
      "source": [
        "# Evaluate all models using the main script with evaluation flags\n",
        "!python main.py --config config.json --evaluate --models densenet resnet efficientnet"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_section"
      },
      "source": [
        "## Visualization with Grad-CAM\n",
        "\n",
        "Visualize model predictions using Grad-CAM for interpretability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grad_cam_code"
      },
      "source": [
        "# Visualize model predictions with Grad-CAM using the main script\n",
        "# Example for DenseNet, change --model to resnet or efficientnet for others\n",
        "!python main.py --config config.json --visualize --model densenet"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## Download Results\n",
        "\n",
        "Download the experimental results and trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results_code"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Zip results and models\n",
        "!zip -r results_and_models.zip experiments/ checkpoints/\n",
        "\n",
        "# Download zip file\n",
        "files.download('results_and_models.zip')"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdYfvdTZQIZ+E77L2SuEBL",
      "last_runtime_duration": 2653518,
      "execution_state": "COMPLETED"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}